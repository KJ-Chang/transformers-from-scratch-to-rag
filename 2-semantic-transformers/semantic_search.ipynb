{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49942672",
   "metadata": {},
   "source": [
    "# 語意搜尋實作 (Semantic Search Implementation)\n",
    "\n",
    "本筆記本展示如何使用 Sentence Transformers 和 FAISS 實現高效的語意搜尋。\n",
    "\n",
    "## 實作步驟與說明\n",
    "\n",
    "1. **環境設置**\n",
    "   - 檢查 GPU 可用性\n",
    "   - 設置計算裝置\n",
    "\n",
    "2. **模型準備**\n",
    "   - 載入預訓練的 Sentence Transformer 模型\n",
    "   - 使用輕量級但高效的 all-MiniLM-L6-v2 模型\n",
    "\n",
    "3. **數據處理**\n",
    "   - 載入 MS MARCO 問答數據集\n",
    "   - 提取文檔和查詢數據\n",
    "\n",
    "4. **向量索引**\n",
    "   - 使用 FAISS 建立高效的向量索引\n",
    "   - 支援 GPU 加速搜尋\n",
    "\n",
    "5. **搜尋評估**\n",
    "   - 執行批次搜尋\n",
    "   - 計算處理時間\n",
    "   - 分析搜尋結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b72b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境設置：檢查 GPU 可用性並設置計算裝置\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'使用的計算裝置: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46256f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入預訓練模型\n",
    "# all-MiniLM-L6-v2 是一個輕量級模型，在效能和速度上取得良好平衡\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "print('模型載入完成')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c467c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入並準備數據\n",
    "# MS MARCO 是微軟發布的大規模機器閱讀理解和問答數據集\n",
    "from datasets import load_dataset\n",
    "\n",
    "print('開始載入數據集...')\n",
    "dataset_name = 'ms_marco'\n",
    "dataset = load_dataset(dataset_name, 'v2.1', split='train').select(range(100000))\n",
    "\n",
    "# 整理文檔和查詢數據\n",
    "documents = [\n",
    "    passage_text\n",
    "    for passages in dataset['passages']\n",
    "    for passage_text in passages['passage_text']\n",
    "]\n",
    "\n",
    "queries = dataset['query']\n",
    "\n",
    "# 隨機選擇查詢樣本進行測試\n",
    "NUM_QUERIES = 10000\n",
    "import random\n",
    "random.shuffle(queries)\n",
    "queries = queries[:NUM_QUERIES]\n",
    "\n",
    "print('數據準備完成')\n",
    "print(f'\\n示例文檔:\\n{documents[0]}')\n",
    "print(f'\\n示例查詢:\\n{queries[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168316d3",
   "metadata": {},
   "source": [
    "## FAISS 向量索引與搜尋\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) 是一個高效能的向量索引和搜尋函式庫：\n",
    "\n",
    "- 支援十億級別的向量搜尋\n",
    "- 提供 GPU 加速功能\n",
    "- 實現多種索引算法\n",
    "- 優化的記憶體使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00dc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "print('開始建立向量索引...')\n",
    "# 將文檔轉換為向量表示\n",
    "fs_documents_embedding = model.encode(documents, batch_size=256, convert_to_tensor=True)\n",
    "fs_documents_embedding_np = fs_documents_embedding.cpu().numpy()\n",
    "\n",
    "# 創建 FAISS 索引 (使用 L2 歐氏距離)\n",
    "dimension = fs_documents_embedding.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# GPU 加速處理\n",
    "if torch.cuda.is_available():\n",
    "    res = faiss.StandardGpuResources()\n",
    "    gpu_index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    index = gpu_index\n",
    "\n",
    "# 添加文檔向量到索引\n",
    "index.add(fs_documents_embedding_np)\n",
    "print(f'向量維度: {dimension}')\n",
    "print('索引建立完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3ffbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import util\n",
    "\n",
    "print('開始執行搜尋...')\n",
    "# 將查詢轉換為向量\n",
    "fs_queries_embedding = model.encode(queries, batch_size=256, convert_to_tensor=True)\n",
    "fs_queries_embedding_np = fs_queries_embedding.cpu().numpy()\n",
    "\n",
    "# 設定每個查詢返回的結果數量\n",
    "top_k = 2\n",
    "\n",
    "# 執行批次搜尋並計時\n",
    "start_time = time.time()\n",
    "D, I = util.batch_search(fs_queries_embedding_np, index, top_k, batch_size=8)\n",
    "end_time = time.time()\n",
    "\n",
    "# 顯示部分搜尋結果\n",
    "print('\\n搜尋結果示例：')\n",
    "for i, (dists, idxs) in enumerate(zip(D, I), 1):\n",
    "    print(f'\\n查詢 {i}: {queries[i-1]}')\n",
    "    for j, (dist, idx) in enumerate(zip(dists, idxs), 1):\n",
    "        print(f'   結果 {j}')\n",
    "        print(f'\\t距離: {dist:.4f}')  # 距離越小表示越相似\n",
    "        print(f'\\t文檔: {documents[idx]}')\n",
    "\n",
    "    # 只顯示前 5 個查詢的結果\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59420670",
   "metadata": {},
   "source": [
    "## 效能分析\n",
    "\n",
    "計算並顯示搜尋效能指標：\n",
    "- 總處理時間\n",
    "- 平均每次查詢時間\n",
    "- GPU 加速效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f82640",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string expression part cannot include a backslash (1930430608.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f'使用設備: {\\\"GPU\\\" if torch.cuda.is_available() else \\CPU\\'}')\u001b[0m\n\u001b[0m                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string expression part cannot include a backslash\n"
     ]
    }
   ],
   "source": [
    "# 計算效能指標\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_query = total_time / NUM_QUERIES\n",
    "\n",
    "print(f'搜尋效能統計：')\n",
    "print(f'總處理時間: {total_time:.2f} 秒')\n",
    "print(f'平均每次查詢時間: {avg_time_per_query*1000:.2f} 毫秒')\n",
    "print(f'查詢總數: {NUM_QUERIES}')\n",
    "print(f'批次大小: 8')\n",
    "print(f'使用設備: {\"GPU\" if torch.cuda.is_available() else \"CPU\"}')\n",
    "print(f'向量維度: {dimension}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76fe629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
